{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import decimal\n",
    "from decimal import *\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from math import exp, sqrt,pi\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset,RandomSampler\n",
    "\n",
    "from mpl_toolkits import mplot3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "eps1 = 1e-4\n",
    "eps2 = 1e-2\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batchflag = True\n",
    "batchsize = 10\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "x = np.linspace(start,end,100 )\n",
    "#x = np.meshgrid(x)\n",
    "x = np.reshape(x, (np.size(x[:]),1))\n",
    "\n",
    "A1 = ((eps1*np.pi**2+1)/(eps2**2*np.pi**2 + (eps1*np.pi**2 + 1)**2))\n",
    "B1 = ((eps2*np.pi)/(eps2**2*np.pi**2 + (eps1*np.pi**2 + 1)**2))\n",
    "muL = ((-eps2 + np.sqrt(eps2**2+4*eps1))/(2*eps1))\n",
    "muR = ((eps2 + np.sqrt(eps2**2+4*eps1))/(2*eps1))\n",
    "A2 = -A1*((1+np.exp(-muR))/(1-np.exp(-muL-muR)))\n",
    "B2 = A1*((1+np.exp(-muL))/(1-np.exp(-muL-muR)))\n",
    "\n",
    "def actual_soln():\n",
    "    return A1*np.cos(np.pi*x) + B1*np.sin(np.pi*x) + A2*np.exp(-muL*x) + B2*np.exp(-muR*(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(soln,soln_name):\n",
    "    x = np.linspace(start,end,100)\n",
    "    plt.plot(x, soln)\n",
    "    plt.title(soln_name)\n",
    "    plt.show()\n",
    "\n",
    "def plot_graphs(actual_soln,pred_soln):\n",
    "\tx = np.linspace(start,end,100)\n",
    "\tplt.plot(x, actual_soln, label = 'Actual solution')\n",
    "\tplt.plot(x, pred_soln, label = 'Predicted solution')\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "\t\n",
    "class Swish(nn.Module):\n",
    "\tdef __init__(self, inplace=True):\n",
    "\t\tsuper(Swish, self).__init__()\n",
    "\t\tself.inplace = inplace\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tif self.inplace:\n",
    "\t\t\tx.mul_(torch.sigmoid(x))\n",
    "\t\t\treturn x\n",
    "\t\telse:\n",
    "\t\t\treturn x * torch.sigmoid(x)\n",
    "\t\n",
    "\n",
    "class FBPINN(nn.Module):\n",
    "\thid_dim = 512\n",
    "\tinput_dim = 1 \n",
    "\tdef __init__(self):\n",
    "\t\tsuper(FBPINN, self).__init__()\n",
    "\t\tself.tanh = nn.Tanh()\n",
    "\t\tself.lin0 = nn.Linear(self.input_dim,self.hid_dim)\n",
    "\t\tself.lin = nn.Linear(self.hid_dim,self.hid_dim)\n",
    "\t\tself.lin1 = nn.Linear(self.hid_dim,1)\n",
    "\t\tself.swish = Swish()\n",
    "\tdef forward(self,x):\t\t\n",
    "\t\ttanh1 = self.tanh(x)\n",
    "\t\ttanh2 = self.tanh(1 - x)\n",
    "\t\ttanh11 = (tanh1[:,0].unsqueeze(1))\n",
    "\t\ttanh22 = (tanh2[:,0].unsqueeze(1))\n",
    "\t\tx = self.lin0(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin(x)\n",
    "\t\tx = self.swish(x)\n",
    "\t\tx = self.lin1(x)\n",
    "\t\tx = x*tanh11*tanh22\n",
    "\t\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(actual_soln(),\"Actual solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(device,x,eps1,eps2,learning_rate,epochs,batch_flag,batch_size):\n",
    "\t\n",
    "\txnet = torch.Tensor(x) \n",
    "\t\n",
    "\tif(batch_flag):\n",
    "\n",
    "\t\tdataset = TensorDataset(xnet)\n",
    "\t\tdataloader = DataLoader(dataset, batch_size=batch_size,shuffle=True,num_workers = 0,drop_last = True )\n",
    "\t\tprint(len(dataloader))\n",
    "\t\t\n",
    "\tnet = FBPINN()#.to(device)\n",
    "\t\n",
    "\tdef init_normal(m):\n",
    "\t\tif type(m) == nn.Linear:\n",
    "\t\t\tnn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\tnet.apply(init_normal)\n",
    "\n",
    "\toptimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\n",
    "\tdef Loss_criterion(xnet):\n",
    "\t\txnet.requires_grad = True\n",
    "\t\tpoints = xnet\n",
    "\t\tU = net(points)\n",
    "\t\tU = U.view(len(U),-1)\n",
    "\t\t\n",
    "\t\t#soln = \n",
    "\n",
    "\t\tf = torch.cos(torch.pi*xnet)\n",
    "\t\tU_x = torch.autograd.grad(U,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tU_xx = torch.autograd.grad(U_x,xnet,grad_outputs=torch.ones_like(xnet),create_graph = True,only_inputs=True)[0]\n",
    "\t\tloss1 = -eps1*U_xx + eps2*U_x + U - f  \n",
    "\t\t\n",
    "\t\treturn nn.MSELoss()(loss1,torch.zeros_like(loss1)) \n",
    "\n",
    "\tlosses = []\n",
    "\ttic = time.time()\n",
    "\n",
    "\tif(batch_flag):\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tif epoch == 50:\n",
    "\t\t\t\tlearning_rate = 0.00001\n",
    "\t\t\t\tnew_optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas = (0.9,0.99),eps = 10**-15)\n",
    "\t\t\t\toptimizer = new_optimizer\n",
    "\t\t\tfor batch_idx,(x_in) in enumerate(dataloader):\n",
    "\t\t\t\t#print(type(batch_idx))\n",
    "\t\t\t\tnet.zero_grad()\n",
    "\t\t\t\tloss = Loss_criterion(x_in[0])\n",
    "\t\t\t\tloss.backward()\n",
    "\t\t\t\toptimizer.step() \n",
    "\t\t\t\tif batch_idx % 20 ==0:\n",
    "\t\t\t\t\tprint('\\nTrain Epoch: {} \\tLoss: {:.20f}'.format(epoch, loss.item()))\n",
    "\n",
    "\t\t\tU = net(xnet)\n",
    "\t\t\tz = U.detach().numpy()\n",
    "\t\t\tif epoch % 10 == 0:\n",
    "\t\t\t\tactual_loss = np.square(actual_soln() - z).mean()\n",
    "\t\t\t\tprint('\\nAfter Epoch {}, \\t Actual solution loss: {:.10f}\\n'.format(epoch, actual_loss))\n",
    "\t\t\tif epoch % 50 == 0:\n",
    "\t\t\t\tplot_graphs(actual_soln(),z)\n",
    "\t\t\t\n",
    "#\t\t\tlosses.append([loss.item(),loss])\n",
    "\n",
    "\ttoc = time.time()\n",
    "\telapseTime = toc - tic\n",
    "\tprint (\"Time elapsed = \", elapseTime)\n",
    "\n",
    "\toutput = net(xnet)  \n",
    "\t\n",
    "\treturn output,losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output,losses = train(device,x,eps1,eps2,learning_rate,epochs,batchflag,batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
